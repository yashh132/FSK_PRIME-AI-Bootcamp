{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L982FdumDCVn"
      },
      "source": [
        "# Task 2: Data Preprocessing for Machine Learning – AI Bootcamp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EEWt7WNF5kP"
      },
      "source": [
        "Download Titanic Dataset here: https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\n",
        "\n",
        "#### About this file\n",
        "\n",
        "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
        "\n",
        "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone on board, resulting in the death of 1502 out of 2224 passengers and crew.\n",
        "\n",
        "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
        "\n",
        "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk9AwRFXDO6n"
      },
      "source": [
        "## Section 1: Data Loading & Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG2LLFb4DSrf"
      },
      "source": [
        "### **Task 1**: Load and Inspect a Dataset\n",
        "\n",
        "*Instruction*: Load the `titanic.csv` dataset and display the first 5 rows. Show basic info and describe statistics of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6YtbgenDSWH",
        "outputId": "d11eebef-4475-4ce2-bfca-af1c9dc8048a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Survived  Pclass                                               Name  \\\n",
            "0         0       3                             Mr. Owen Harris Braund   \n",
            "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
            "2         1       3                              Miss. Laina Heikkinen   \n",
            "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
            "4         0       3                            Mr. William Henry Allen   \n",
            "\n",
            "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
            "0    male  22.0                        1                        0   7.2500  \n",
            "1  female  38.0                        1                        0  71.2833  \n",
            "2  female  26.0                        0                        0   7.9250  \n",
            "3  female  35.0                        1                        0  53.1000  \n",
            "4    male  35.0                        0                        0   8.0500  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 887 entries, 0 to 886\n",
            "Data columns (total 8 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   Survived                 887 non-null    int64  \n",
            " 1   Pclass                   887 non-null    int64  \n",
            " 2   Name                     887 non-null    object \n",
            " 3   Sex                      887 non-null    object \n",
            " 4   Age                      887 non-null    float64\n",
            " 5   Siblings/Spouses Aboard  887 non-null    int64  \n",
            " 6   Parents/Children Aboard  887 non-null    int64  \n",
            " 7   Fare                     887 non-null    float64\n",
            "dtypes: float64(2), int64(4), object(2)\n",
            "memory usage: 55.6+ KB\n",
            "None\n",
            "         Survived      Pclass         Age  Siblings/Spouses Aboard  \\\n",
            "count  887.000000  887.000000  887.000000               887.000000   \n",
            "mean     0.385569    2.305524   29.471443                 0.525366   \n",
            "std      0.487004    0.836662   14.121908                 1.104669   \n",
            "min      0.000000    1.000000    0.420000                 0.000000   \n",
            "25%      0.000000    2.000000   20.250000                 0.000000   \n",
            "50%      0.000000    3.000000   28.000000                 0.000000   \n",
            "75%      1.000000    3.000000   38.000000                 1.000000   \n",
            "max      1.000000    3.000000   80.000000                 8.000000   \n",
            "\n",
            "       Parents/Children Aboard       Fare  \n",
            "count               887.000000  887.00000  \n",
            "mean                  0.383315   32.30542  \n",
            "std                   0.807466   49.78204  \n",
            "min                   0.000000    0.00000  \n",
            "25%                   0.000000    7.92500  \n",
            "50%                   0.000000   14.45420  \n",
            "75%                   0.000000   31.13750  \n",
            "max                   6.000000  512.32920  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('titanic.csv')\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03CKwCBtDzRL"
      },
      "source": [
        "## Section 2: Handling Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh1W_9m5DuzF"
      },
      "source": [
        "### **Task 2**: Identify and Handle Missing Data\n",
        "\n",
        "*Instruction*:\n",
        "\n",
        "\n",
        "\n",
        "*   Display the number of missing values per column.\n",
        "*   Fill missing `Age` values with the median.\n",
        "*   Drop the second row in the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQTsWR6GDn6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ccd044-6dc3-4a07-ad07-ec783be1c7b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values per column:\n",
            " Name     0\n",
            "Age      1\n",
            "Score    1\n",
            "dtype: int64\n",
            "\n",
            "Final DataFrame:\n",
            "       Name   Age  Score\n",
            "0    Alice  25.0   85.0\n",
            "2  Charlie  30.0    NaN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-82fb47d4d5ea>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(median_age, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [25, None, 30],\n",
        "    'Score': [85, 90, None]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "\n",
        "median_age = df['Age'].median()\n",
        "df['Age'].fillna(median_age, inplace=True)\n",
        "\n",
        "\n",
        "df.drop(index=1, inplace=True)\n",
        "\n",
        "\n",
        "print(\"\\nFinal DataFrame:\\n\", df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVV1BgZvEE3a"
      },
      "source": [
        "## Section 3: Encoding Categorical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opUK7Z7LEIr4"
      },
      "source": [
        "### **Task 3**: Convert Categorical to Numeric\n",
        "\n",
        "*Instruction*: Convert `Sex` and `Pclass` columns to numeric using:\n",
        "\n",
        "\n",
        "*   Label Encoding for `Sex`\n",
        "*   One-Hot Encoding for `Pclass`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UW3FMdjQEEl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7c9448-1ae5-4b82-d021-c8f402c6fd01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Name  Sex  Pclass_1  Pclass_2  Pclass_3\n",
            "0    Alice    0      True     False     False\n",
            "1      Bob    1     False     False      True\n",
            "2  Charlie    1     False      True     False\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Sex': ['female', 'male', 'male'],\n",
        "    'Pclass': [1, 3, 2]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['Sex'] = le.fit_transform(df['Sex'])\n",
        "\n",
        "\n",
        "df = pd.get_dummies(df, columns=['Pclass'], prefix='Pclass')\n",
        "\n",
        "\n",
        "print(df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNO0DPi3EpgF"
      },
      "source": [
        "## Section 4: Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W74DNGaJEtdj"
      },
      "source": [
        "### **Task 4**: Scale Numerical Features\n",
        "\n",
        "*Instruction*: Use StandardScaler to scale the Age and Fare columns.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aM8iWEAXEOmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9866c027-2fd1-4db4-ec37-92e4f2304628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Name       Age      Fare\n",
            "0    Alice -0.980581 -0.720286\n",
            "1      Bob  1.372813  1.414131\n",
            "2  Charlie -0.392232 -0.693845\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [22, 38, 26],\n",
        "    'Fare': [7.25, 71.83, 8.05]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])\n",
        "\n",
        "print(df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFxPFagsE9mS"
      },
      "source": [
        "## Section 5: Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZwIOzHXFD1a"
      },
      "source": [
        "### **Task 5**: Build Preprocessing Pipeline\n",
        "\n",
        "*Instruction*: Using `ColumnTransformer` and `Pipeline` from `sklearn`, build a pipeline that:\n",
        "\n",
        "\n",
        "\n",
        "*   Imputes missing values\n",
        "*   Scales numeric data\n",
        "*   Encodes categorical data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpUFTR1JFDWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8415e19-2a14-4a3e-9ced-d1e71088e514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Age      Fare  Sex_female  Sex_male  Pclass_1  Pclass_2  Pclass_3\n",
            "0 -1.224745  1.224745         0.0       1.0       1.0       0.0       0.0\n",
            "1  0.000000 -1.224745         1.0       0.0       0.0       0.0       1.0\n",
            "2  1.224745  0.000000         1.0       0.0       0.0       1.0       0.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "data = {\n",
        "    'Age': [25, None, 30],\n",
        "    'Fare': [72.5, 10.5, None],\n",
        "    'Sex': ['male', 'female', 'female'],\n",
        "    'Pclass': [1, 3, 2]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "numeric_features = ['Age', 'Fare']\n",
        "categorical_features = ['Sex', 'Pclass']\n",
        "\n",
        "\n",
        "numeric_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_pipeline, numeric_features),\n",
        "    ('cat', categorical_pipeline, categorical_features)\n",
        "])\n",
        "\n",
        "\n",
        "processed_data = preprocessor.fit_transform(df)\n",
        "\n",
        "\n",
        "column_names = (\n",
        "    numeric_features +\n",
        "    list(preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_features))\n",
        ")\n",
        "\n",
        "processed_df = pd.DataFrame(processed_data, columns=column_names)\n",
        "\n",
        "print(processed_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-OY1jI5IaIB"
      },
      "source": [
        "## Section 6: Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeBCcr3RIi-8"
      },
      "source": [
        "### **Task 6**: Create a New Feature\n",
        "\n",
        "*Instruction*: Create a new feature `FamilySize` = `Siblings/Spouses Aboard` + `Parents/Children Aboard` + 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSza6VScIakN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b63e9c1-0151-4348-9e93-1da0a1a929e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Age      Fare  FamilySize  Sex_female  Sex_male  Pclass_1  Pclass_2  \\\n",
            "0 -1.224745 -0.720286   -1.224745         0.0       1.0       0.0       0.0   \n",
            "1  0.000000  1.414131    0.000000         1.0       0.0       1.0       0.0   \n",
            "2  1.224745 -0.693845    1.224745         1.0       0.0       0.0       1.0   \n",
            "\n",
            "   Pclass_3  \n",
            "0       1.0  \n",
            "1       0.0  \n",
            "2       0.0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "data = {\n",
        "    'SibSp': [1, 0, 2],\n",
        "    'Parch': [0, 2, 1],\n",
        "    'Age': [22, None, 30],\n",
        "    'Fare': [7.25, 71.83, 8.05],\n",
        "    'Sex': ['male', 'female', 'female'],\n",
        "    'Pclass': [3, 1, 2]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "class FamilySizeAdder(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X['FamilySize'] = X['SibSp'] + X['Parch'] + 1\n",
        "        return X\n",
        "\n",
        "\n",
        "numeric_features = ['Age', 'Fare', 'FamilySize']\n",
        "categorical_features = ['Sex', 'Pclass']\n",
        "\n",
        "\n",
        "numeric_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_pipeline, numeric_features),\n",
        "    ('cat', categorical_pipeline, categorical_features)\n",
        "])\n",
        "\n",
        "\n",
        "full_pipeline = Pipeline([\n",
        "    ('family_size_adder', FamilySizeAdder()),\n",
        "    ('preprocessing', preprocessor)\n",
        "])\n",
        "\n",
        "\n",
        "processed_data = full_pipeline.fit_transform(df)\n",
        "\n",
        "\n",
        "encoded_cat = full_pipeline.named_steps['preprocessing'].named_transformers_['cat']['encoder'] \\\n",
        "    .get_feature_names_out(categorical_features)\n",
        "\n",
        "feature_names = numeric_features + list(encoded_cat)\n",
        "\n",
        "\n",
        "processed_df = pd.DataFrame(processed_data, columns=feature_names)\n",
        "print(processed_df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}